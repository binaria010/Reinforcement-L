{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q-learning\n",
    "\n",
    "This notebook will guide you through implementation of vanilla Q-learning algorithm.\n",
    "\n",
    "You need to implement QLearningAgent (follow instructions for each method) and use it on a number of tests below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "#XVFB will be launched if you run on a server\n",
    "import os\n",
    "if type(os.environ.get(\"DISPLAY\")) is not str or len(os.environ.get(\"DISPLAY\")) == 0:\n",
    "    !bash ../xvfb start\n",
    "    os.environ['DISPLAY'] = ':1'\n",
    "        \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting qlearning.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile qlearning.py\n",
    "from collections import defaultdict\n",
    "import random, math\n",
    "import numpy as np\n",
    "\n",
    "class QLearningAgent:\n",
    "    def __init__(self, alpha, epsilon, discount, get_legal_actions):\n",
    "        \"\"\"\n",
    "        Q-Learning Agent\n",
    "        based on http://inst.eecs.berkeley.edu/~cs188/sp09/pacman.html\n",
    "        Instance variables you have access to\n",
    "          - self.epsilon (exploration prob)\n",
    "          - self.alpha (learning rate)\n",
    "          - self.discount (discount rate aka gamma)\n",
    "\n",
    "        Functions you should use\n",
    "          - self.get_legal_actions(state) {state, hashable -> list of actions, each is hashable}\n",
    "            which returns legal actions for a state\n",
    "          - self.get_qvalue(state,action)\n",
    "            which returns Q(state,action)\n",
    "          - self.set_qvalue(state,action,value)\n",
    "            which sets Q(state,action) := value\n",
    "\n",
    "        !!!Important!!!\n",
    "        Note: please avoid using self._qValues directly. \n",
    "            There's a special self.get_qvalue/set_qvalue for that.\n",
    "        \"\"\"\n",
    "\n",
    "        self.get_legal_actions = get_legal_actions\n",
    "        self._qvalues = defaultdict(lambda: defaultdict(lambda: 0))\n",
    "        self.alpha = alpha\n",
    "        self.epsilon = epsilon\n",
    "        self.discount = discount\n",
    "\n",
    "    def get_qvalue(self, state, action):\n",
    "        \"\"\" Returns Q(state,action) \"\"\"\n",
    "        return self._qvalues[state][action]\n",
    "\n",
    "    def set_qvalue(self,state,action,value):\n",
    "        \"\"\" Sets the Qvalue for [state,action] to the given value \"\"\"\n",
    "        self._qvalues[state][action] = value\n",
    "\n",
    "    #---------------------START OF YOUR CODE---------------------#\n",
    "\n",
    "    def get_value(self, state):\n",
    "        \"\"\"\n",
    "        Compute your agent's estimate of V(s) using current q-values\n",
    "        V(s) = max_over_action Q(state,action) over possible actions.\n",
    "        Note: please take into account that q-values can be negative.\n",
    "        \"\"\"\n",
    "        possible_actions = self.get_legal_actions(state)\n",
    "\n",
    "        #If there are no legal actions, return 0.0\n",
    "        if len(possible_actions) == 0:\n",
    "            return 0.0\n",
    "\n",
    "        value = max(self.get_qvalue(state,action) for action in possible_actions)\n",
    "\n",
    "        return value\n",
    "\n",
    "    def update(self, state, action, reward, next_state):\n",
    "        \"\"\"\n",
    "        You should do your Q-Value update here:\n",
    "           Q(s,a) := (1 - alpha) * Q(s,a) + alpha * (r + gamma * V(s'))\n",
    "        \"\"\"\n",
    "\n",
    "        #agent parameters\n",
    "        gamma = self.discount\n",
    "        learning_rate = self.alpha\n",
    "        \n",
    "        \n",
    "        new_qvalue = (1-learning_rate)*self.get_qvalue(state,action) + learning_rate*(reward + gamma*self.get_value(next_state))\n",
    "        \n",
    "        self.set_qvalue(state, action, new_qvalue)\n",
    "\n",
    "    \n",
    "    def get_best_action(self, state):\n",
    "        \"\"\"\n",
    "        Compute the best action to take in a state (using current q-values). \n",
    "        \"\"\"\n",
    "        possible_actions = self.get_legal_actions(state)\n",
    "\n",
    "        #If there are no legal actions, return None\n",
    "        if len(possible_actions) == 0:\n",
    "            return None\n",
    "        \n",
    "        best_action_idx = np.argmax([self.get_qvalue(state,action) for action in possible_actions])\n",
    "        best_action = possible_actions[best_action_idx]\n",
    "\n",
    "        return best_action\n",
    "\n",
    "    def get_action(self, state):\n",
    "        \"\"\"\n",
    "        Compute the action to take in the current state, including exploration.  \n",
    "        With probability self.epsilon, we should take a random action.\n",
    "            otherwise - the best policy action (self.getPolicy).\n",
    "        \n",
    "        Note: To pick randomly from a list, use random.choice(list). \n",
    "              To pick True or False with a given probablity, generate uniform number in [0, 1]\n",
    "              and compare it with your probability\n",
    "        \"\"\"\n",
    "        # this is the epsilon greedy policy: where we choose the best action with porb 1-epsilon, \n",
    "        # and choose random action with probability epsilon\n",
    "\n",
    "        # Pick Action\n",
    "        possible_actions = self.get_legal_actions(state)\n",
    "        action = None\n",
    "\n",
    "        #If there are no legal actions, return None\n",
    "        if len(possible_actions) == 0:\n",
    "            return None\n",
    "\n",
    "        #agent parameters:\n",
    "        epsilon = self.epsilon\n",
    "\n",
    "        p = np.random.uniform(0,1)\n",
    "        if p <= epsilon:\n",
    "                chosen_action = np.asscalar(np.random.choice(possible_actions,1,epsilon))\n",
    "        else :\n",
    "                chosen_action = self.get_best_action(state)\n",
    "        return chosen_action"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try it on taxi\n",
    "\n",
    "Here we use the qlearning agent on taxi env from openai gym.\n",
    "You will need to insert a few agent functions here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import gym\n",
    "env = gym.make(\"Taxi-v3\")\n",
    "\n",
    "n_actions = env.action_space.n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from qlearning import QLearningAgent\n",
    "\n",
    "agent = QLearningAgent(alpha=0.5, epsilon=0.25, discount=0.99,\n",
    "                       get_legal_actions = lambda s: range(n_actions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new_qvalue is  -0.5\n",
      "range(0, 6)\n",
      "113\n",
      "0\n",
      "3\n",
      "133\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "s=env.reset()\n",
    "a = agent.get_action(s)\n",
    "next_s, r, done, _ = env.step(a)\n",
    "alpha =0.5\n",
    "discount = 0.99\n",
    "new_qvalue = (1-alpha)*agent.get_qvalue(s,a) + alpha*(r + discount*agent.get_value(next_s))\n",
    "print(\"new_qvalue is \", new_qvalue)\n",
    "print(agent.get_legal_actions(s))\n",
    "print(s)\n",
    "print(agent.get_best_action(s))\n",
    "print(agent.get_action(s))\n",
    "print(next_s)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def play_and_train(env,agent,t_max=10**4):\n",
    "    \"\"\"\n",
    "    This function should \n",
    "    - run a full game, actions given by agent's e-greedy policy\n",
    "    - train agent using agent.update(...) whenever it is possible\n",
    "    - return total reward\n",
    "    \"\"\"\n",
    "    total_reward = 0.0\n",
    "    s = env.reset()\n",
    "    \n",
    "    for t in range(t_max):\n",
    "        # get agent to pick action given state s.\n",
    "        a = agent.get_action(s)\n",
    "    \n",
    "        next_s, r, done, _ = env.step(a)\n",
    "        \n",
    "        # train (update) agent for state s\n",
    "        agent.update(s, a, r,next_s)\n",
    "        \n",
    "        s = next_s\n",
    "        total_reward +=r\n",
    "        if done: break\n",
    "        \n",
    "    return total_reward\n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-578.0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "play_and_train(env,agent,10**4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eps = 2.9191091959171894e-05 mean reward = 9.1\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import clear_output\n",
    "\n",
    "rewards = []\n",
    "for i in range(1000):\n",
    "    rewards.append(play_and_train(env, agent))\n",
    "    agent.epsilon *= 0.99\n",
    "    \n",
    "    if i %100 ==0:\n",
    "        clear_output(True)\n",
    "        print('eps =', agent.epsilon, 'mean reward =', np.mean(rewards[-10:]))\n",
    "        plt.plot(rewards)\n",
    "        plt.show()\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submit to Coursera I: Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submit_rewards1 = rewards.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binarized state spaces\n",
    "\n",
    "Use agent to train efficiently on CartPole-v0.\n",
    "This environment has a continuous set of possible states, so you will have to group them into bins somehow.\n",
    "\n",
    "The simplest way is to use `round(x,n_digits)` (or numpy round) to round real number to a given amount of digits.\n",
    "\n",
    "The tricky part is to get the n_digits right for each state to train effectively.\n",
    "\n",
    "Note that you don't need to convert state to integers, but to __tuples__ of any kind of values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make(\"CartPole-v0\")\n",
    "n_actions = env.action_space.n\n",
    "\n",
    "print(\"first state:%s\" % (env.reset()))\n",
    "plt.imshow(env.render('rgb_array'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Play a few games\n",
    "\n",
    "We need to estimate observation distributions. To do so, we'll play a few games and record all states."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_states = []\n",
    "for _ in range(1000):\n",
    "    all_states.append(env.reset())\n",
    "    done = False\n",
    "    while not done:\n",
    "        s, r, done, _ = env.step(env.action_space.sample())\n",
    "        all_states.append(s)\n",
    "        if done: break\n",
    "            \n",
    "all_states = np.array(all_states)\n",
    "\n",
    "print(all_states[990:1000,:])\n",
    "for obs_i in range(env.observation_space.shape[0]):\n",
    "    plt.hist(all_states[:, obs_i], bins=20)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binarize environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from gym.core import ObservationWrapper\n",
    "class Binarizer(ObservationWrapper):\n",
    "    \n",
    "    def observation(self, state):    \n",
    "        \n",
    "        decimals=np.array([1, 1,100,10])\n",
    "        state = np.round(state*decimals)/decimals\n",
    "        #state = <round state to some amount digits.>\n",
    "        #hint: you can do that with round(x,n_digits)\n",
    "        #you will need to pick a different n_digits for each dimension\n",
    "\n",
    "        return tuple(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "env = Binarizer(gym.make(\"CartPole-v0\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_states = []\n",
    "for _ in range(100):\n",
    "    all_states.append(env.reset())\n",
    "    done = False\n",
    "    while not done:\n",
    "        s, r, done, _ = env.step(env.action_space.sample())\n",
    "        all_states.append(s)\n",
    "        if done: break\n",
    "            \n",
    "all_states = np.array(all_states)\n",
    "\n",
    "for obs_i in range(env.observation_space.shape[0]):\n",
    "    \n",
    "    plt.hist(all_states[:,obs_i],bins=20)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learn binarized policy\n",
    "\n",
    "Now let's train a policy that uses binarized state space.\n",
    "\n",
    "__Tips:__ \n",
    "* If your binarization is too coarse, your agent may fail to find optimal policy. In that case, change binarization. \n",
    "* If your binarization is too fine-grained, your agent will take much longer than 1000 steps to converge. You can either increase number of iterations and decrease epsilon decay or change binarization.\n",
    "* Having 10^3 ~ 10^4 distinct states is recommended (`len(QLearningAgent._qvalues)`), but not required.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "agent = QLearningAgent(alpha=0.5, epsilon=0.25, discount=0.99,\n",
    "                       get_legal_actions=lambda s: range(n_actions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rewards2 = []\n",
    "for i in range(1000):\n",
    "    rewards2.append(play_and_train(env,agent))   \n",
    "    \n",
    "    #OPTIONAL YOUR CODE: adjust epsilon\n",
    "    if i %100 ==0:\n",
    "        clear_output(True)\n",
    "        print('eps =', agent.epsilon, 'mean reward =', np.mean(rewards2[-10:]))\n",
    "        plt.plot(rewards2)\n",
    "        plt.show()\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submit to Coursera II: Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submit_rewards2 = rewards2.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from submit import submit_qlearning\n",
    "submit_qlearning(submit_rewards1, submit_rewards2, 'juli.osorio@gmail.com', '1l1bfW6UuhD5p9Qq')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
